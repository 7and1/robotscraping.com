name = "robot-scraping-core"
main = "src/index.ts"
compatibility_date = "2024-10-01"
compatibility_flags = ["nodejs_compat"]

[browser]
binding = "MYBROWSER"

[[d1_databases]]
binding = "DB"
database_name = "robot-db"
database_id = "8c56033f-b93e-4f8c-b836-7b2a291db59c"

[[r2_buckets]]
binding = "BUCKET"
bucket_name = "robot-snapshots"

[[queues.producers]]
queue = "robot-tasks"
binding = "TASK_QUEUE"

[[queues.consumers]]
queue = "robot-tasks"
max_batch_size = 1
max_batch_timeout = 60

[triggers]
crons = ["* * * * *"]

[ai]
binding = "AI"

[vars]
AI_PROVIDER = "cloudflare"
OPENAI_MODEL = "gpt-4o-mini"
ANTHROPIC_MODEL = "claude-3-haiku-20240307"
MAX_CONTENT_CHARS = "20000"
BROWSER_TIMEOUT_MS = "15000"
CORS_ORIGIN = "*"
DEFAULT_SCREENSHOT = "false"
STORE_CONTENT = "true"
WEBHOOK_SECRET = "change-me"
ALLOW_ANON = "false"
CACHE_ENABLED = "true"
CACHE_TTL_MS = "900000"
PROXY_GRID_ENABLED = "false"
PROXY_GRID_BASE_URL = "http://google.savedimage.com"
PROXY_GRID_ALLOWLIST = ""
PROXY_GRID_FORCE = "false"
